{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#*********************Importing the packages required********************************\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport cv2\nfrom PIL import Image\nfrom warnings import filterwarnings\nfilterwarnings(\"ignore\")\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow import greater\nimport os\nfrom matplotlib import pyplot as plt\nimport cv2\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPool2D, Dropout, SpatialDropout2D, BatchNormalization, Input, Activation, Dense, Flatten\nfrom keras.optimizers import Adam, RMSprop\nfrom keras.callbacks import ReduceLROnPlateau, EarlyStopping\nfrom keras.utils import plot_model\nfrom keras.losses import binary_crossentropy\nfrom keras.applications.vgg19 import VGG19\nfrom sklearn.metrics import confusion_matrix, accuracy_score, precision_score,f1_score,recall_score\nimport seaborn as sns\nfrom tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\nimport time\n#****************************************************************************","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Loading the frontal face detector using cascadeClassifier\nface_model = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n#Method to plot the training history\ndef plot_loss_acc(history):\n    #plt.plot(history.history['loss'],label='training loss')\n    #plt.plot(history.history['val_loss'],label='validation loss')\n    plt.plot(history.history['accuracy'],label='training accuracy')\n    plt.plot(history.history['val_accuracy'],label='validation accuracy')\n    plt.xlabel('# epochs')\n    plt.ylabel('loss')\n    plt.legend()\n    plt.show()\n    \n#Method to detect faces in input image and tell wheher face mask is worn or not\ndef detect_masks(img,model):\n    mask_label = {1:'MASK',0:'NO MASK'}\n    dist_label = {1:(0,255,0),0:(255,0,0)}\n    img = cv2.imread(img)\n    img = cv2.cvtColor(img, cv2.IMREAD_GRAYSCALE)#converting the input image to greay image\n    faces = face_model.detectMultiScale(img,scaleFactor=1.1, minNeighbors=4) #returns coordinates of faces\n    label = [0 for i in range(len(faces))]\n    new_img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR) #colored output image\n    for i in range(len(faces)):\n        (x,y,w,h) = faces[i]\n        crop = new_img[y:y+h,x:x+w]\n        crop = cv2.resize(crop,(HEIGHT,WEIGHT))\n        crop = np.reshape(crop,[1,HEIGHT,WEIGHT,3])/255.0\n        mask_result = model.predict_classes(crop) # checking if mask is worn or not\n        #print(mask_result[0][0])\n        cv2.putText(new_img,mask_label[mask_result[0][0]],(x, y-10),cv2.FONT_HERSHEY_SIMPLEX,0.5,dist_label[mask_result[0][0]],2)\n        cv2.rectangle(new_img,(x,y),(x+w,y+h),dist_label[mask_result[0][0]],1)\n    plt.figure(figsize=(10,10))\n    plt.imshow(new_img)\n    \n#method to split the image data generator values into labels and X\ndef split_X_Y(gen):\n    temp_x = []\n    temp_y = []\n    for i in range(gen.__len__()):\n        tempnext = gen.next()\n        temp_x.append(tempnext[0])\n        temp_y.append(tempnext[1])\n    x=np.concatenate(temp_x)\n    y=np.concatenate(temp_y)\n    return (x,y)\n\n#Method to plot confusion metrix, accuracy,recall, and F1 score of model\ndef plot_confusion_matrix(model):\n    ypred = model.predict_classes(x_test)\n    sns.heatmap(confusion_matrix(ypred,y_test),annot=True,cbar=False,fmt = '.1f',xticklabels=['No Mask','Mask'],yticklabels=['No Mask','Mask'],cmap = 'Blues')\n    title = 'Test Confusion Matrix, Accuracy:' + str(round(accuracy_score(ypred,y_test),4))\n    plt.title(title,fontsize=18)\n    plt.xlabel('Predicted Labels')\n    plt.ylabel('True Labels')\n    print('Precision:' + str(round(precision_score(ypred,y_test),4)))\n    print('Recall:' + str(round(recall_score(ypred,y_test),4)))\n    print('F1 score:' + str(round(f1_score(ypred,y_test),4)))\n#**************************************************************************","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"#********************Data preprocessing and preparation********************\n#creating Imagedatagenerator for train data\ntrain_data_generator = ImageDataGenerator(rescale=1./255,\n                                         zoom_range=0.2,\n                                         shear_range=0.2,\n                                         horizontal_flip=True)\n#creating Imagedatagenerator for test data\ntest_data_generator = ImageDataGenerator(rescale=1./255)\n#creating Imagedatagenerator for val data\nvalidation_data_generator = ImageDataGenerator(rescale=1./255,\n                                         zoom_range=0.2,\n                                         shear_range=0.2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"#loading the paths of dataset\ntrain_dirs = \"face-mask-12k-images-dataset/Face Mask Dataset/Train\"\ntest_dirs = \"face-mask-12k-images-dataset/Face Mask Dataset/Test\"\nvalidation_dirs = \"face-mask-12k-images-dataset/Face Mask Dataset/Validation\"\n#Defining the input size\nHEIGHT = 120\nWEIGHT = 120\n#To generate datasets or image augmentaion using imagedatagenerators created earlier\nprint(\"Flowing Train\")\ntrain_generator = train_data_generator.flow_from_directory(\n        train_dirs,\n        target_size=(HEIGHT,WEIGHT),\n        batch_size=80,\n        interpolation=\"nearest\",\n        class_mode='binary',\n        classes=[\"WithoutMask\",\"WithMask\"])\n\nprint(\"\\nFlowing Test\")\ntest_generator = test_data_generator.flow_from_directory(\n        test_dirs,\n        target_size=(HEIGHT,WEIGHT),\n        batch_size=80,\n        interpolation=\"nearest\",\n        class_mode='binary',\n        classes=[\"WithoutMask\",\"WithMask\"])\n\nprint(\"\\nFlowing Validation\")\nvalidation_generator = validation_data_generator.flow_from_directory(\n        validation_dirs,\n        target_size=(HEIGHT,WEIGHT),\n        batch_size=80,\n        interpolation=\"nearest\",\n        class_mode='binary',\n        classes=[\"WithoutMask\",\"WithMask\"])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#splitting train,test,val datasets into corresponding labels and X\nx_train,y_train = split_X_Y(train_generator)\nx_test,y_test = split_X_Y(test_generator)\nx_val,y_val = split_X_Y(validation_generator)\nprint(x_train.shape,y_train.shape)\nprint(x_test.shape,y_test.shape)\nprint(x_val.shape,y_val.shape)\n#***********************************************************************","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Building","metadata":{}},{"cell_type":"code","source":"#**********************Model buildng and training******************************\n#Modified VGG19 model creation\ndef build_VGG19():\n    vgg19 = VGG19(weights='imagenet',include_top=False,input_shape=(HEIGHT,WEIGHT,3))\n    #To keep the layers untrainable\n    for layer in vgg19.layers:\n        layer.trainable = False\n        \n    model = Sequential()\n    model.add(vgg19) #adding the VGG19 to the network\n    model.add(Flatten()) #flatteing the features into vector\n    model.add(Dense(1,activation='sigmoid')) #output layer\n    model.summary()\n    optimizer = Adam(lr=0.001) #optimizer with learnng rate\n    model.compile(optimizer=optimizer,metrics =[\"accuracy\"],loss = binary_crossentropy)\n    #adding earlystopping and Reducer to stop training when further model improvement is not noticed\n    reducer = ReduceLROnPlateau(monitor='loss',patience=3,factor=0.75,min_lr=0.000001,verbose=1)\n    stopSign = EarlyStopping(monitor = \"loss\",patience=20,min_delta=0.000000000001,mode=\"min\")\n    epochs = 20\n    batch_size = 32\n    steps_per_epoch = x_train.shape[0] // batch_size\n    #fitting the model using training data\n    history = model.fit(x_train,y_train,\n                        epochs = epochs, \n                        validation_data = (x_val,y_val),\n                        verbose = 1,\n                        batch_size=batch_size,\n                        steps_per_epoch = steps_per_epoch,\n                        callbacks=[reducer,stopSign])\n    return history,model\n\n#building modified MobileNetv2 model\ndef build_MobileNetv2():\n    mobilenet = MobileNetV2(weights='imagenet',include_top=False,input_shape=(HEIGHT,WEIGHT,3))\n    #setting the layers untrainable\n    for layer in mobilenet.layers:\n        layer.trainable = False\n    model = Sequential()\n    model.add(mobilenet) #adding mobilenet to network\n    model.add(Flatten()) #creating the feature vector\n    model.add(Dense(1,activation='sigmoid')) #output layer\n    model.summary()\n    optimizer = Adam(lr=0.001)\n    model.compile(optimizer=optimizer,metrics =[\"accuracy\"],loss = binary_crossentropy)\n    #adding earlystopping and reducer to stop training if training accuracy stops improving\n    reducer = ReduceLROnPlateau(monitor='loss',patience=3,factor=0.75,min_lr=0.000001,verbose=1)\n    stopSign = EarlyStopping(monitor = \"loss\",patience=20,min_delta=0.000000000001,mode=\"min\")\n    epochs = 20\n    batch_size = 32\n    steps_per_epoch = x_train.shape[0] // batch_size\n    #fitting the model using training dataset\n    history = model.fit(x_train,y_train,\n                        epochs = epochs, \n                        validation_data = (x_val,y_val),\n                        verbose = 1,\n                        batch_size=batch_size,\n                        steps_per_epoch = steps_per_epoch,\n                        callbacks=[reducer,stopSign])\n    return history,model\n\n#building model with 1 CNN layer and 3 FC layers\ndef build_cnn_1():\n        model = Sequential()\n        \n        model.add(Input(shape=(HEIGHT,WEIGHT,3,))) # adding input layer\n\n        model.add(Conv2D(filters=16,kernel_size=(2,2),padding=\"same\")) #adding CNN layer\n        model.add(Activation(\"relu\"))\n        model.add(SpatialDropout2D(0.25))\n        model.add(MaxPool2D(pool_size=(4,4))) #Max pooling\n\n        model.add(Flatten()) #Flatteing the features into vector\n        \n        model.add(Dense(2048)) # 1st FC layer\n        model.add(Activation(\"relu\"))\n        model.add(Dropout(0.25))\n        \n        model.add(Dense(1024)) #2nd FC layer\n        model.add(Activation(\"relu\"))\n        model.add(Dropout(0.2))\n        \n        \n        model.add(Dense(1)) # 3rd FC layer/output\n        model.add(Activation(\"sigmoid\"))\n        \n        optimizer = Adam(lr=0.001)\n        model.compile(optimizer = optimizer ,metrics=[\"accuracy\"], loss = binary_crossentropy)\n        model.summary()\n        #earlystoping and reducer to stop training if accuracy stops improving\n        reducer = ReduceLROnPlateau(monitor='loss',patience=3,factor=0.75,min_lr=0.000001,verbose=1)\n        stopSign = EarlyStopping(monitor = \"loss\",patience=20,min_delta=0.000000000001,mode=\"min\")\n\n        epochs = 20\n        batch_size = 32\n        steps_per_epoch = x_train.shape[0] // batch_size\n        #fitting the model using training dataset\n        history = model.fit(x_train,y_train,\n                    epochs = epochs, \n                    validation_data = (x_val,y_val),\n                    verbose = 1,\n                    batch_size=batch_size,\n                    steps_per_epoch = steps_per_epoch,\n                    callbacks=[reducer,stopSign])\n        \n        return history,model\n\n#Building model with 2 CNN layers and 3 FC layers\ndef build_cnn_2_3fl():\n        model = Sequential()\n        \n        model.add(Input(shape=(HEIGHT,WEIGHT,3,))) #Input layer\n\n        model.add(Conv2D(filters=16,kernel_size=(2,2),padding=\"same\")) #1st CNN layer\n        model.add(Activation(\"relu\"))\n        model.add(SpatialDropout2D(0.25))\n        model.add(MaxPool2D(pool_size=(4,4)))\n\n        model.add(Conv2D(filters=32,kernel_size=(2,2),padding=\"same\")) #2nd CNN layer\n        model.add(Activation(\"relu\"))\n        model.add(SpatialDropout2D(0.25))\n        model.add(MaxPool2D(pool_size=(4,4),strides=(4,4)))\n               \n        model.add(Flatten()) #Vectorising the features\n        \n        model.add(Dense(2048)) #1st FC layer\n        model.add(Activation(\"relu\"))\n        model.add(Dropout(0.25))\n        \n        model.add(Dense(1024)) #2nd FC layer\n        model.add(Activation(\"relu\"))\n        model.add(Dropout(0.2))\n        \n        \n        model.add(Dense(1)) #3rd FC layer/output\n        model.add(Activation(\"sigmoid\"))\n        \n        optimizer = Adam(lr=0.001)\n        model.compile(optimizer = optimizer ,metrics=[\"accuracy\"], loss = binary_crossentropy)\n        model.summary()\n        reducer = ReduceLROnPlateau(monitor='loss',patience=3,factor=0.75,min_lr=0.000001,verbose=1)\n        stopSign = EarlyStopping(monitor = \"loss\",patience=20,min_delta=0.000000000001,mode=\"min\")\n        epochs = 20\n        batch_size = 32\n        steps_per_epoch = x_train.shape[0] // batch_size\n        #fitting the model using training data\n        history = model.fit(x_train,y_train,\n                    epochs = epochs, \n                    validation_data = (x_val,y_val),\n                    verbose = 1,\n                    batch_size=batch_size,\n                    steps_per_epoch = steps_per_epoch,\n                    callbacks=[reducer,stopSign])\n        \n        return history,model\n    \n#Building model with 2 CNN layers and 2 FC layers\ndef build_cnn_2_2fl():\n        model = Sequential()\n        \n        model.add(Input(shape=(HEIGHT,WEIGHT,3,))) #Input layer\n\n        model.add(Conv2D(filters=16,kernel_size=(2,2),padding=\"same\"))#1st CNN layer\n        model.add(Activation(\"relu\"))\n        model.add(SpatialDropout2D(0.25))\n        model.add(MaxPool2D(pool_size=(4,4)))\n\n        model.add(Conv2D(filters=32,kernel_size=(2,2),padding=\"same\"))#2nd CNN layer\n        model.add(Activation(\"relu\"))\n        model.add(SpatialDropout2D(0.25))\n        model.add(MaxPool2D(pool_size=(4,4),strides=(4,4)))\n               \n        model.add(Flatten())\n        \n        model.add(Dense(1024)) #1st FC layer\n        model.add(Activation(\"relu\"))\n        model.add(Dropout(0.2))\n        \n        \n        model.add(Dense(1)) #2nd FC layer\n        model.add(Activation(\"sigmoid\"))\n        \n        optimizer = Adam(lr=0.001)\n        model.compile(optimizer = optimizer ,metrics=[\"accuracy\"], loss = binary_crossentropy)\n        model.summary()\n        reducer = ReduceLROnPlateau(monitor='loss',patience=3,factor=0.75,min_lr=0.000001,verbose=1)\n        stopSign = EarlyStopping(monitor = \"loss\",patience=20,min_delta=0.000000000001,mode=\"min\")\n        epochs = 20\n        batch_size = 32\n        steps_per_epoch = x_train.shape[0] // batch_size\n        #fitting the model using taining dataset\n        history = model.fit(x_train,y_train,\n                    epochs = epochs, \n                    validation_data = (x_val,y_val),\n                    verbose = 1,\n                    batch_size=batch_size,\n                    steps_per_epoch = steps_per_epoch,\n                    callbacks=[reducer,stopSign])\n        \n        return history,model\n\n#buildng the model with 3 CNN layers and 3 FC layers\ndef build_cnn_3():\n    model = Sequential()\n\n    model.add(Input(shape=(HEIGHT,WEIGHT,3,))) #input layer\n\n    model.add(Conv2D(filters=16,kernel_size=(2,2),padding=\"same\")) #1st CNN layer\n    model.add(Activation(\"relu\"))\n    model.add(SpatialDropout2D(0.25))\n    model.add(MaxPool2D(pool_size=(4,4)))\n\n    model.add(Conv2D(filters=16,kernel_size=(2,2),padding=\"same\")) #2nd CNN layer\n    model.add(Activation(\"relu\"))\n    model.add(SpatialDropout2D(0.25))\n    model.add(MaxPool2D(pool_size=(4,4)))\n\n    model.add(Conv2D(filters=16,kernel_size=(2,2),padding=\"same\")) #3rd CNN layer\n    model.add(Activation(\"relu\"))\n    model.add(SpatialDropout2D(0.25))\n    model.add(MaxPool2D(pool_size=(4,4),strides=(4,4)))\n\n    model.add(Flatten())\n\n    model.add(Dense(2048)) #1st FC layer\n    model.add(Activation(\"relu\"))\n    model.add(Dropout(0.25))\n\n    model.add(Dense(1024)) #2nd FC layer\n    model.add(Activation(\"relu\"))\n    model.add(Dropout(0.2))\n\n\n    model.add(Dense(1)) #3rd FC layer/output layer\n    model.add(Activation(\"sigmoid\"))\n\n    optimizer = Adam(lr=0.001)\n    model.compile(optimizer = optimizer ,metrics=[\"accuracy\"], loss = binary_crossentropy)\n    model.summary()\n    reducer = ReduceLROnPlateau(monitor='loss',patience=3,factor=0.75,min_lr=0.000001,verbose=1)\n    stopSign = EarlyStopping(monitor = \"loss\",patience=20,min_delta=0.000000000001,mode=\"min\")\n    epochs = 20\n    batch_size = 32\n    steps_per_epoch = x_train.shape[0] // batch_size\n    #fitting the model using train dataset\n    history = model.fit(x_train,y_train,\n                epochs = epochs, \n                validation_data = (x_val,y_val),\n                verbose = 1,\n                batch_size=batch_size,\n                steps_per_epoch = steps_per_epoch,\n                callbacks=[reducer,stopSign])\n\n    return history,model\n#*******************************************************************","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#********************Transfer Lerning using VGG19********************\nstart = time.time()\nhistory_VGG19,model_VGG19 = build_VGG19() #building model\nend = time.time()\nprint(\"Training time:\" + str(end - start))\nstart = time.time()\nmodel_VGG19.evaluate(x_test,y_test) #Evaluating model\nend = time.time()\nprint(\"Testing time:\" + str(end - start))\nplot_confusion_matrix(model_VGG19) #displaying evaluation metrics\n#********************************************************************","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#********************Transfer Lerning using MobileNetV2********************\nstart = time.time()\nhistory_mobnet,model_mobnet = build_MobileNetv2() #building model\nend = time.time()\nprint(\"Training time:\" + str(end - start))\nstart = time.time()\nmodel_mobnet.evaluate(x_test,y_test) #evaluating model\nend = time.time()\nprint(\"Testing time:\" + str(end - start))\nplot_confusion_matrix(model_mobnet) #displaying evaluation metrics\n#***************************************************************************","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#********************transfer learning-training accuracy and loss***************\nplt.plot(history_VGG19.history['accuracy'],label='VGG19 train')\nplt.plot(history_VGG19.history['val_accuracy'],label='VGG19 val')\nplt.plot(history_mobnet.history['accuracy'],label='MobileNetV2 train')\nplt.plot(history_mobnet.history['val_accuracy'],label='MobileNetV2 val')\nplt.xlabel('# epochs')\nplt.ylabel('Accuracy')\nplt.title(\"Model Accuracy\")\nplt.legend()\nplt.show()\n\nplt.plot(history_VGG19.history['loss'],label='VGG19 train')\nplt.plot(history_VGG19.history['val_loss'],label='VGG19 val')\nplt.plot(history_mobnet.history['loss'],label='MobileNetV2 train')\nplt.plot(history_mobnet.history['val_loss'],label='MobileNetV2 val')\nplt.xlabel('# epochs')\nplt.title(\"Model Loss\")\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n#**********************************************************************","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#loading image to detect face mask\nimg_path = '/kaggle/input/d/andrewmvd/face-mask-detection/images/maksssksksss96.png'\n#calling method to detect mask\ndetect_masks(img_path,model_VGG19)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#********************Model with 1 CNN and 3 FC********************\nstart = time.time()\nhistory_cnn1,model_cnn1 = build_cnn_1()\nend = time.time()\nprint(\"Training time:\" + str(end - start))\nstart = time.time()\nmodel_cnn1.evaluate(x_test,y_test)\nend = time.time()\nprint(\"Testing time:\" + str(end - start))\nplot_confusion_matrix(model_cnn1)\n#*****************************************************************","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#********************Model with 2 CNN and 2 FC********************\nstart = time.time()\nhistory_cnn2_1,model_cnn2_1 = build_cnn_2_2fl()\nend = time.time()\nprint(\"Training time:\" + str(end - start))\nstart = time.time()\nmodel_cnn2_1.evaluate(x_test,y_test)\nend = time.time()\nprint(\"Testing time:\" + str(end - start))\nplot_confusion_matrix(model_cnn2_1)\n#*****************************************************************","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#********************Model with 2 CNN and 3 FC********************\nstart = time.time()\nhistory_cnn2_2,model_cnn2_2 = build_cnn_2_3fl()\nend = time.time()\nprint(\"Training time:\" + str(end - start))\nstart = time.time()\nmodel_cnn2_2.evaluate(x_test,y_test)\nend = time.time()\nprint(\"Testing time:\" + str(end - start))\nplot_confusion_matrix(model_cnn2_2)\n#*****************************************************************\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#********************Model with 3 CNN and 3 FC********************\nstart = time.time()\nhistory_cnn3,model_cnn3 = build_cnn_3()\nend = time.time()\nprint(\"Training time:\" + str(end - start))\nstart = time.time()\nmodel_cnn3.evaluate(x_test,y_test)\nend = time.time()\nprint(\"Testing time:\" + str(end - start))\nplot_confusion_matrix(model_cnn3)\n#******************************************************************\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#********************CNN training accuracy and loss********************\nplt.plot(history_cnn1.history['accuracy'],label='CNN1 3FC train')\nplt.plot(history_cnn1.history['val_accuracy'],label='CNN1 3FC val')\nplt.plot(history_cnn2_1.history['accuracy'],label='CNN2 2FC train')\nplt.plot(history_cnn2_1.history['val_accuracy'],label='CNN2 2FC val')\nplt.plot(history_cnn2_2.history['accuracy'],label='CNN2 3FC train')\nplt.plot(history_cnn2_2.history['val_accuracy'],label='CNN2 3FC val')\nplt.plot(history_cnn3.history['accuracy'],label='CNN3 3FC train')\nplt.plot(history_cnn3.history['val_accuracy'],label='CNN3 3FC val')\nplt.xlabel('# epochs')\nplt.ylabel('Accuracy')\nplt.title(\"Model Accuracy\")\nplt.legend()\nplt.show()\n\nplt.plot(history_cnn1.history['loss'],label='CNN1 3FC train')\nplt.plot(history_cnn1.history['val_loss'],label='CNN1 3FC val')\nplt.plot(history_cnn2_1.history['loss'],label='CNN2 2FC train')\nplt.plot(history_cnn2_1.history['val_loss'],label='CNN2 2FC val')\nplt.plot(history_cnn2_2.history['loss'],label='CNN2 3FC train')\nplt.plot(history_cnn2_2.history['val_loss'],label='CNN2 3FC val')\nplt.plot(history_cnn3.history['loss'],label='CNN3 3FC train')\nplt.plot(history_cnn3.history['val_loss'],label='CNN3 3FC val')\nplt.xlabel('# epochs')\nplt.title(\"Model Loss\")\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n#***********************************************************************","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Using CNN AutoEncoders","metadata":{}},{"cell_type":"code","source":"#********************Future research using AutoEncoders********************\n# import keras\n# from keras import layers\n# input_img = keras.Input(shape=(HEIGHT,WEIGHT,3,))\n# def encode_cnn_ae():\n# #     x = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n# #     x = layers.MaxPooling2D((4, 4), padding='same')(x)\n#     x = layers.Conv2D(3, (3, 3), activation='relu', padding='same')(input_img)\n#     encoded = layers.MaxPooling2D((4, 4), padding='same')(x)\n# #     x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n# #     encoded = layers.MaxPooling2D((4, 4), padding='same')(x)\n#     return encoded\n\n# def decode_cnn_ae(encoded):\n# #     x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n# #     x = layers.UpSampling2D((4, 4))(x)\n#     x = layers.Conv2D(3, (3, 3), activation='relu', padding='same')(encoded)\n#     decoded = layers.UpSampling2D((4, 4))(x)\n# #     x = layers.Conv2D(16, (3, 3), activation='relu')(x)\n# #     x = layers.UpSampling2D((4, 4))(x)\n# #     decoded = layers.Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n#     return decoded\n\n# def fully_connected(enco):\n#     flat = Flatten()(enco)\n#     den = Dense(2048, activation='relu')(flat)\n#     den1 = Dense(1024, activation='relu')(den)\n#     out = Dense(1, activation='softmax')(den1)\n#     return out\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# autoencoder = keras.Model(input_img, decode_cnn_ae(encode_cnn_ae()))\n# autoencoder.compile(optimizer='adam', loss='binary_crossentropy')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# autoencoder.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# autoencoder.layers","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# trained_ae = autoencoder.fit(x_train, x_train,\n#                 epochs=20,\n#                 batch_size=128,\n#                 shuffle=True,\n#                 validation_data=(x_val, x_val))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# encoder = encode_cnn_ae()\n# full_model = keras.Model(input_img,fully_connected(encoder))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# full_model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ### set fully conected veights for the required layers same as encoder decoder part\n# for l1,l2 in zip(full_model.layers[:3],autoencoder.layers[0:3]):\n#     l1.set_weights(l2.get_weights())\n# # set encoder part veights not trainable\n# for layer in full_model.layers:\n#     layer.trainable = False\n\n# #Compile the fully connected model\n# full_model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n# full_model.summary()\n# #Train the fuly connected model to learn the lables and classification\n# classify_train = full_model.fit(x_train, y_train, epochs=20,verbose=1)#, batch_size=64","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# decoded_imgs = autoencoder.predict(x_test)\n\n# n = 4\n# plt.figure(figsize=(10, 4))\n# for i in range(1, n + 1):\n#     # Display original\n#     ax = plt.subplot(2, n, i)\n#     plt.imshow(x_test[i])\n#     plt.gray()\n#     ax.get_xaxis().set_visible(False)\n#     ax.get_yaxis().set_visible(False)\n\n#     # Display reconstruction\n#     ax = plt.subplot(2, n, i + n)\n#     plt.imshow(decoded_imgs[i])\n#     plt.gray()\n#     ax.get_xaxis().set_visible(False)\n#     ax.get_yaxis().set_visible(False)\n# plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# full_model.evaluate(x_test,y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pred = full_model.predict(x_train)\n# pred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from tensorflow.keras.layers import LeakyReLU\n# from tensorflow.keras.models import Model\n# # encoder level 1\n# e = Dense(2000)(input_img)\n# e = BatchNormalization()(e)\n# e = LeakyReLU()(e)\n# # encoder level 2\n# e = Dense(1000)(e)\n# e = BatchNormalization()(e)\n# e = LeakyReLU()(e)\n# # bottleneck\n# #n_bottleneck = round(float(1000) / 2.0)\n# bottleneck = Dense(1000)(e)\n# # define decoder, level 1\n# d = Dense(1000)(bottleneck)\n# d = BatchNormalization()(d)\n# d = LeakyReLU()(d)\n# # decoder level 2\n# d = Dense(2000)(d)\n# d = BatchNormalization()(d)\n# d = LeakyReLU()(d)\n# # output layer\n# output = Dense(1, activation='softmax')(d)\n# # define autoencoder model\n# model = Model(inputs=input_img, outputs=output)\n# # compile autoencoder model\n# model.compile(optimizer='adam', loss='mse')\n# # plot the autoencoder\n# # fit the autoencoder model to reconstruct input\n# history = model.fit(x_train, x_train, epochs=200, batch_size=16, verbose=2, validation_data=(x_val,x_val))\n# # plot loss\n# pyplot.plot(history.history['loss'], label='train')\n# pyplot.plot(history.history['val_loss'], label='test')\n# pyplot.legend()\n# pyplot.show()\n# # define an encoder model (without the decoder)\n# encoder = Model(inputs=visible, outputs=bottleneck)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}